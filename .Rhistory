quarter_hour_readings %>% filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz=UTC))
quarter_hour_readings %>% filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC"))
set.seed(99)
data <- as.data.frame(matrix( sample( 0:20 , 15 , replace=F) , ncol=5))
colnames(data) <- c("math" , "english" , "biology" , "music" , "R-coding" )
rownames(data) <- paste("mister" , letters[1:3] , sep="-")
data
data <- rbind(rep(20,5) , rep(0,5) , data)
data
radarchart(data)
latest <- lf %>% filter(date_time == max(date_time)) %>%
column_to_rownames(var="site_id")
latest <- lf %>% filter(date_time == max(date_time)) %>%
column_to_rownames(var="site_id")
lf %>% filter(date_time == max(date_time))
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id")
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time) %>%
rbind(rep(20,5))
rbind(rep(20,5),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
radarchart(dat)
dat
ex <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(ambient_air_temperature))
ex
radarchart(ex)
library(ggplot2)
library(fmsb)
latest <- lf %>% filter(date_time == max(date_time)) %>%
column_to_rownames(var="site_id")
library(ggplot2)
library(fmsb)
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
radarchart(dat)
# Read the data (hosted on the gallery website)
data <- read.table("https://python-graph-gallery.com/wp-content/uploads/bike.csv", header=T, sep=",") %>% head(300)
data
# Since my time is currently a factor, I have to convert it to a date-time format!
data$datetime <- ymd_hms(data$datetime)
# Then you can create the xts necessary to use dygraph
don <- xts(x = data$count, order.by = data$datetime)
install.packages("xts")
# Library
library(dygraphs)
library(xts)          # To make the convertion data-frame / xts format
library(tidyverse)
library(lubridate)
# Read the data (hosted on the gallery website)
data <- read.table("https://python-graph-gallery.com/wp-content/uploads/bike.csv", header=T, sep=",") %>% head(300)
# Check type of variable
# str(data)
# Since my time is currently a factor, I have to convert it to a date-time format!
data$datetime <- ymd_hms(data$datetime)
# Then you can create the xts necessary to use dygraph
don <- xts(x = data$count, order.by = data$datetime)
# Finally the plot
p <- dygraph(don) %>%
dyOptions(labelsUTC = TRUE, fillGraph=TRUE, fillAlpha=0.1, drawGrid = FALSE, colors="#D8AE5A") %>%
dyRangeSelector() %>%
dyCrosshair(direction = "vertical") %>%
dyHighlight(highlightCircleSize = 5, highlightSeriesBackgroundAlpha = 0.2, hideOnMouseOut = FALSE)  %>%
dyRoller(rollPeriod = 1)
p
library(readr)
library(tidyverse)
sensor_locations <- read_csv(here::here("Data/Microclimate_Sensor_Locations.csv"))
sensor_readings <- read_csv(here::here("Data/Microclimate_Sensor_Readings.csv"))
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time)
#extracting only quarter hourly readings
quarter_hour_readings <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
select(-id, -units, -type) %>%
pivot_wider(names_from = sensor_id,
values_from = value) %>%
unnest(c("5a", "5b", "5c", "6", "0a", "0b")) %>%
rename("ambient_air_temperature" ="5a",
"relative_humidy" = "5b",
"barometric_pressure" = "5c",
"particulate_density_2.5" = "0a",
"particulate_density_10" = "0b",
"average_wind_speed" = "6")
shiny::runApp()
runApp()
runApp()
install.packages("shinythemes")
runApp()
ggplot(data = data.frame(ftitle = "Ambient Air Temperature")) +
facet_wrap(~ ftitle) +  geom_smooth(data = quarter_hour_readings,
aes(x = date_time,
y = ambient_air_temperature,
color = site_id)) +
scale_colour_manual(name = "Site",
labels = c("Between 87 and 89 Grattan Street, Carlton",
"Corner of Swanston and Grattan Streets, Carlton",
"Corner of Pelham and Leicester Streets, Carlton",
"141 Grattan Street, Carlton",
"3/121 Grattan Street, Carlton"),
values=c("#E15759",
"#59A14F",
"#76B7B2",
"#F28E2B",
"#4E79A7")) +
theme_minimal() +
theme(legend.position="bottom", legend.direction="vertical") +
labs(x = "",
y = "Â°C")+
scale_x_datetime(date_breaks = "months" , date_labels = "%b-%y")
sensor_locations
runApp()
runApp()
runApp()
runApp()
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
select(-id, -units, -type)
data
sensor_locations
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
select(-id, -units, -type)
data
data %>%
ggplot(aes(x = date_time, y = value, color = sensor_id)) +
geom_line()
data %>%
ggplot(aes(x = date_time, y = value, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id)
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
select(-id, -units, -type)
data %>%
ggplot(aes(x = date_time, y = value, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free")
data %>%
ggplot(aes(x = date_time, y = value, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1)
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d")))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d"))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"),
hour = as.Date(date_time, "%h", tz = "UTC"))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"),
hour = format(date_time, "%H:%M"))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"),
hour = format(date_time, "%H"))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"),
hour = format(date_time, "%H")) %>%
select(-id, -units, -type)
data
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d", tz = "UTC"),
hour = format(date_time, "%H")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = format(date_time, "%H")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = format(date_time, "%H")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = format(date_time, "%Y-%m-%d %H")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = parse_date_time(format(date_time, "%Y-%m-%d %H")),'%Y %m %d %I') %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = parse_date_time(format(date_time, "%Y-%m-%d %H")),'%Y %m %d %H') %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = format(round(date_time, units="hours"), format="%Y-%m-%d %H:%M"))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = format(round(date_time, units="hours"), format="%Y-%m-%d %H:%M"))%>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = format(round(date_time, units="hours"), format="%Y-%m-%d %H:%M"))%>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = format(date_time, "%Y-%m-%d %H")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = format(round(date_time, units="hours", tz = "UTC"), format="%Y-%m-%d %H:%M"))%>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date) %>%
summarise(hourly_avg = mean(value))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = format(date_time, "%Y-%m-%d %H:00")) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M:%S')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(date = as.Date(date_time, "%Y-%m-%d %H", tz = "UTC"),
hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, date, hour) %>%
summarise(hourly_avg = mean(value))
data
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, datetime) %>%
summarise(hourly_avg = mean(value))
hourly_avg %>%
ggplot(aes(x = datetime, y = hourly_avg, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1)
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, datetime) %>%
summarise(hourly_avg = mean(value))
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time)
sensor_readings <- read_csv(here::here("Data/Microclimate_Sensor_Readings.csv"))
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time)
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = hour = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime =  parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, datetime) %>%
summarise(hourly_avg = mean(value))
hourly_avg %>%
ggplot(aes(x = datetime, y = hourly_avg, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1)
hourly_avg %>%
ggplot(aes(x = datetime, y = hourly_avg, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1) %>%
theme_minimal()
hourly_avg %>%
ggplot(aes(x = datetime, y = hourly_avg, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1) +
theme_minimal()
library(plotly)
ggplotly(
hourly_avg %>%
ggplot(aes(x = datetime, y = hourly_avg, color = site_id)) +
geom_line() +
facet_wrap(~sensor_id, scales = "free", ncol = 1) +
theme_minimal())
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(lubridate)
library(kableExtra)
library(GGally)
sensor_readings <- read_csv(here::here("Data/Microclimate_Sensor_Readings.csv"))
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time)
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
sensor_locations
sensor_locations <- read_csv(here::here("Data/Microclimate_Sensor_Locations.csv"))
sensor_locations
runApp()
runApp()
sensor_locations
runApp()
runApp()
runApp()
runApp()
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, datetime) %>%
summarise(hourly_avg = mean(value))
hourly_avg
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time) %>%
left_join(sensor_locations, by = c("site_id"="site_id"))
library(readr)
library(tidyverse)
library(shiny)
library(shinydashboard)
library(shinythemes)
library(lubridate)
library(plotly)
library(leaflet)
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time) %>%
left_join(sensor_locations, by = c("site_id"="site_id"))
runApp()
sensor_locations <- read_csv(here::here("Data/Microclimate_Sensor_Locations.csv"))
sensor_readings <- read_csv(here::here("Data/Microclimate_Sensor_Readings.csv"))
# converting date time from char to dttm format
sensor_readings <- sensor_readings %>%
mutate(date_time = parse_date_time(local_time,'%Y %m %d %I:%M:%S %p')) %>%
select(-local_time) %>%
left_join(sensor_locations, by = c("site_id"="site_id"))
sensor_readings
hourly_avg <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
mutate(datetime = parse_date_time(format(date_time, "%Y-%m-%d %H:00"),'%Y %m %d %H:%M')) %>%
select(-id, -units, -type) %>%
group_by(site_id, sensor_id, datetime, description) %>%
summarise(hourly_avg = mean(value))
hourly_avg
runApp()
runApp()
runApp()
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(ggplot2)
library(fmsb)
library(plotly)
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
quarter_hour_readings <- sensor_readings %>%
filter(!grepl("EPA", sensor_id)) %>%
select(-id, -units, -type) %>%
pivot_wider(names_from = sensor_id,
values_from = value) %>%
unnest(c("5a", "5b", "5c", "6", "0a", "0b")) %>%
rename("ambient_air_temperature" ="5a",
"relative_humidy" = "5b",
"barometric_pressure" = "5c",
"particulate_density_2.5" = "0a",
"particulate_density_10" = "0b",
"average_wind_speed" = "6")
library(ggplot2)
library(fmsb)
library(plotly)
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
radarchart(dat)
library(ggplot2)
library(fmsb)
library(plotly)
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(-date_time))
radarchart(dat)
quarter_hour_readings
dat
dat <- rbind(c(85.00,100.00,2000.00,160.00,999.9,1999.9),
c(-40.00,0.00,10.00,0.00,0.00,0.00),
quarter_hour_readings %>%
filter(date_time == as.POSIXct("2019-11-15 09:15:00",tz="UTC")) %>%
column_to_rownames(var="site_id") %>%
select(c("ambient_air_temperature","relative_humidy","barometric_pressure", "average_wind_speed", "particulate_density_2.5", "particulate_density_10")))
radarchart(dat)
quarter_hour_readings
xx <- quarter_hour_readings %>% select(c("site_id", "date_time","latitude", "longitude","ambient_air_temperature","relative_humidy","barometric_pressure", "average_wind_speed", "particulate_density_2.5", "particulate_density_10")
xx <- quarter_hour_readings %>% select(c("site_id", "date_time","latitude", "longitude","ambient_air_temperature","relative_humidy","barometric_pressure", "average_wind_speed", "particulate_density_2.5", "particulate_density_10"))
xx <- quarter_hour_readings %>% select("site_id", "date_time","latitude", "longitude","ambient_air_temperature","relative_humidy","barometric_pressure", "average_wind_speed", "particulate_density_2.5", "particulate_density_10")
x
xx
runApp()
runApp()
radarchart(dat)
radarchart(dat)
